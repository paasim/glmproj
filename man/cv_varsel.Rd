% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv_varsel.R
\name{cv_varsel}
\alias{cv_varsel}
\alias{cv_varsel.default}
\alias{cv_varsel.refmodel}
\title{Cross-validated variable selection (varsel)}
\usage{
cv_varsel(object, ...)

\method{cv_varsel}{default}(object, ...)

\method{cv_varsel}{refmodel}(
  object,
  method = NULL,
  cv_method = NULL,
  ndraws = NULL,
  nclusters = NULL,
  ndraws_pred = NULL,
  nclusters_pred = NULL,
  cv_search = TRUE,
  nterms_max = NULL,
  intercept = NULL,
  penalty = NULL,
  verbose = TRUE,
  nloo = NULL,
  K = NULL,
  lambda_min_ratio = 1e-05,
  nlambda = 150,
  thresh = 1e-06,
  regul = 1e-04,
  validate_search = TRUE,
  seed = NULL,
  search_terms = NULL,
  ...
)
}
\arguments{
\item{object}{Either a \code{refmodel}-type object created by
\link[=get_refmodel]{get_refmodel}, a \link[=init_refmodel]{init_refmodel},
an object which can be converted to a reference model using
\link[=get_refmodel]{get_refmodel} or a \code{vsel} object resulting from
\code{varsel} or \code{cv_varsel}.}

\item{...}{Additional arguments to be passed to the
\code{get_refmodel}-function.}

\item{method}{The method used in the variable selection. Possible options are
\code{'L1'} for L1-search and \code{'forward'} for forward selection.
Default is 'forward' if the number of variables in the full data is at most
20,' and \code{'L1'} otherwise.}

\item{cv_method}{The cross-validation method, either 'LOO' or 'kfold'.
Default is 'LOO'.}

\item{ndraws}{Number of posterior draws used for selection. Ignored if
nclusters is provided or if method='L1'. Default is 10.}

\item{nclusters}{Number of clusters used for selection. Defaults to 10 and
ignored if method='L1' (L1-search uses always one cluster).}

\item{ndraws_pred}{Number of projected draws used for prediction (after
selection). Ignored if nclusters_pred is given. Note that setting less
draws or clusters than posterior draws in the reference model may result in
slightly inaccurate projection performance, although increasing this
argument linearly affects the computation time. Default is 400.}

\item{nclusters_pred}{Number of clusters used for prediction (after
selection). Default is 400.}

\item{cv_search}{If TRUE, then the projected coefficients after L1-selection
are computed without any penalization (or using only the regularization
determined by \code{regul}). If FALSE, then the coefficients are the
solution from the' L1-penalized projection. This option is relevant only if
\code{method}='L1'. Default is TRUE for genuine reference models and FALSE
if \code{object} is datafit (see \link[=init_refmodel]{init_refmodel}).}

\item{nterms_max}{Maximum number of varibles until which the selection is
continued. Defaults to min(20, D, floor(0.4*n)) where n is the number of
observations and D the number of variables.}

\item{intercept}{Whether to use intercept in the submodels. Defaults to TRUE.}

\item{penalty}{Vector determining the relative penalties or costs for the
variables. Zero means that those variables have no cost and will therefore
be selected first, whereas Inf means those variables will never be
selected. Currently works only if method == 'L1'. By default 1 for each
variable.}

\item{verbose}{Whether to print out some information during the validation,
Default is TRUE.}

\item{nloo}{Number of observations used to compute the LOO validation
(anything between 1 and the total number of observations). Smaller values
lead to faster computation but higher uncertainty (larger errorbars) in the
accuracy estimation. Default is to use all observations, but for faster
experimentation, one can set this to a small value such as 100. Only
applicable if \code{cv_method = 'LOO'}.}

\item{K}{Number of folds in the K-fold cross validation. Default is 5 for
genuine reference models and 10 for datafits (that is, for penalized
maximum likelihood estimation).}

\item{lambda_min_ratio}{Ratio between the smallest and largest lambda in the
L1-penalized search. This parameter essentially determines how long the
search is carried out, i.e., how large submodels are explored. No need to
change the default value unless the program gives a warning about this.}

\item{nlambda}{Number of values in the lambda grid for L1-penalized search.
No need to change unless the program gives a warning about this.}

\item{thresh}{Convergence threshold when computing L1-path. Usually no need
to change this.}

\item{regul}{Amount of regularization in the projection. Usually there is no
need for regularization, but sometimes for some models the projection can
be ill-behaved and we need to add some regularization to avoid numerical
problems.}

\item{validate_search}{Whether to cross-validate also the selection process,
that is, whether to perform selection separately for each fold. Default is
TRUE and we strongly recommend not setting this to FALSE, because this is
known to bias the accuracy estimates for the selected submodels. However,
setting this to FALSE can sometimes be useful because comparing the results
to the case where this parameter is TRUE gives idea how strongly the
feature selection is (over)fitted to the data (the difference corresponds
to the search degrees of freedom or the effective number of parameters
introduced by the selectin process).}

\item{seed}{Random seed used in the subsampling LOO. By default uses a fixed
seed.}

\item{search_terms}{User defined list of terms to consider for selection.}
}
\value{
An object of type \code{vsel} that contains information about the
  feature selection. The fields are not meant to be accessed directly by the
  user but instead via the helper functions (see the vignettes or type
  ?projpred to see the main functions in the package.)
}
\description{
Perform cross-validation for the projective variable selection for a
generalized linear model or generalized lienar and additive multilevel
models.
}
\examples{
\donttest{
if (requireNamespace('rstanarm', quietly=TRUE)) {
  ### Usage with stanreg objects
  n <- 30
  d <- 5
  x <- matrix(rnorm(n*d), nrow=n)
  y <- x[,1] + 0.5*rnorm(n)
  data <- data.frame(x,y)
  fit <- rstanarm::stan_glm(y ~ X1 + X2 + X3 + X4 + X5, gaussian(),
     data=data, chains=2, iter=500)
  cvs <- cv_varsel(fit)
  plot(cvs)
}
}

}
